# -*- coding: utf-8 -*-
"""Asl_project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zwsWp-b4M1x81ytLRg9VoiILJR6HmF2y
"""

import os
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.utils.data import Dataset
import torchvision.transforms as transforms
from torchvision import models

"""# Importing Dataset"""

# ==========================
# üß† Unified ASL Dataset Setup (Digits + Alphabets)
# ==========================
import os
import zipfile
import shutil
from google.colab import files
from google.colab import drive

# Mount Google Drive (optional if you want to save models later)
drive.mount('/content/drive', force_remount=True)

# --- Step 1: Setup Kaggle credentials ---
print("üîë Please upload your Kaggle API key (kaggle.json).")
uploaded = files.upload()

if "kaggle.json" not in uploaded:
    raise ValueError("‚ùå kaggle.json file is required to download datasets.")

os.makedirs("/root/.kaggle", exist_ok=True)
shutil.move("kaggle.json", "/root/.kaggle/kaggle.json")
os.chmod("/root/.kaggle/kaggle.json", 600)
print("‚úÖ Kaggle API configured successfully!")

# --- Step 2: Download Datasets ---
!kaggle datasets download -d grassknoted/asl-alphabet
!kaggle datasets download -d javaidahmadwani/sign-language-digits-dataset

# --- Step 3: Extract datasets ---
os.makedirs("/content/datasets", exist_ok=True)

def safe_extract(zip_path, target_dir):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(target_dir)
    print(f"‚úÖ Extracted: {os.path.basename(zip_path)}")

safe_extract("/content/asl-alphabet.zip", "/content/datasets/asl_alphabet")
safe_extract("/content/sign-language-digits-dataset.zip", "/content/datasets/sign_digits")

# --- Step 4: Merge both datasets into unified folder ---
merged_root = "/content/Sign-Language-Digits-Dataset/Dataset"
os.makedirs(merged_root, exist_ok=True)

def move_images(source_root, target_root):
    for label_folder in os.listdir(source_root):
        src = os.path.join(source_root, label_folder)
        dst = os.path.join(target_root, label_folder)
        if not os.path.isdir(src):
            continue
        os.makedirs(dst, exist_ok=True)
        for file in os.listdir(src):
            src_file = os.path.join(src, file)
            dst_file = os.path.join(dst, file)
            if os.path.isfile(src_file):
                shutil.copy(src_file, dst_file)

# --- Merge ASL alphabets ---
alphabet_path = "/content/datasets/asl_alphabet/asl_alphabet_train/asl_alphabet_train"
if os.path.exists(alphabet_path):
    print("üìÇ Merging ASL Alphabets...")
    move_images(alphabet_path, merged_root)
else:
    print("‚ö†Ô∏è Alphabet dataset path not found!")

# --- Merge Sign Language Digits ---
digits_root = "/content/datasets/sign_digits/Sign-Language-Digits-Datase"
if os.path.exists(digits_root):
    print("üìÇ Merging ASL Digits...")
    for subset in ["train", "test", "valid"]:
        subset_path = os.path.join(digits_root, subset)
        if not os.path.exists(subset_path):
            continue
        for folder in os.listdir(subset_path):
            # Digits are named "A0", "A1", etc. Rename properly:
            if folder.startswith("A") and folder[1:].isdigit():
                digit_name = folder[1:]  # extract numeric part
            else:
                digit_name = folder
            src_folder = os.path.join(subset_path, folder)
            dst_folder = os.path.join(merged_root, digit_name)
            os.makedirs(dst_folder, exist_ok=True)
            for img in os.listdir(src_folder):
                src_file = os.path.join(src_folder, img)
                dst_file = os.path.join(dst_folder, img)
                if os.path.isfile(src_file):
                    shutil.copy(src_file, dst_file)
else:
    print("‚ö†Ô∏è Digits dataset path not found!")

print("‚úÖ Merged alphabets and digits into:", merged_root)

# --- Step 5: Verify structure ---
print("üìÅ Sample structure:")
!find /content/Sign-Language-Digits-Dataset/Dataset -maxdepth 2 -type d | head -20

"""# Create Dataset Class"""

class SignLanguageDigits(Dataset):
    def __init__(self, root_dir, shape, train=True, transform=None):
        self.root_dir = root_dir
        self.transform = transform or transforms.Compose([
            transforms.Resize(shape),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        self.image_paths = []
        self.labels = []

        # Use all folders (0‚Äì9 + A‚ÄìZ)
        all_labels = sorted(os.listdir(root_dir))
        label_map = {lbl: idx for idx, lbl in enumerate(all_labels)}

        # Split each folder 80/20
        for lbl in all_labels:
            label_dir = os.path.join(root_dir, lbl)
            if not os.path.isdir(label_dir):
                continue
            images = [img for img in os.listdir(label_dir) if img.lower().endswith(('.jpg', '.png'))]
            split_idx = int(0.8 * len(images))
            subset = images[:split_idx] if train else images[split_idx:]

            for img_name in subset:
                self.image_paths.append(os.path.join(label_dir, img_name))
                self.labels.append(label_map[lbl])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)
        return image, label


# ==========================
# üß™ Data Loaders
# ==========================
batch_size = 64

train_dataset = SignLanguageDigits(
    root_dir='/content/Sign-Language-Digits-Dataset/Dataset',
    shape=(64, 64),
    train=True
)

test_dataset = SignLanguageDigits(
    root_dir='/content/Sign-Language-Digits-Dataset/Dataset',
    shape=(64, 64),
    train=False
)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print(f"‚úÖ Loaded {len(train_dataset)} training samples and {len(test_dataset)} testing samples.")

"""# Create and Train CNN"""

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)   # 3 input image channels (RGB), 6 output channels, 5x5 square convolution kernel
        self.conv2 = nn.Conv2d(6, 16, 5)  # 6 input channels (RGB), 16 output channels, 5x5 square convolution kernel
        self.pool = nn.MaxPool2d(2, 2)
        # Calculate the correct size for the first linear layer
        # For 64x64 input:
        # After conv1 (5x5 kernel): 64-5+1 = 60x60
        # After pool1 (2x2): 30x30
        # After conv2 (5x5 kernel): 30-5+1 = 26x26
        # After pool2 (2x2): 13x13
        # So final size is 16*13*13 = 2704
        self.fc1 = nn.Linear(16 * 13 * 13, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 39)

    def forward(self, x):
        # Max pooling over a (2, 2) window
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


# Training setup for the CNN
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Create CNN model
cnn_model = Net().to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)

num_epochs = 10

for epoch in range(num_epochs):
    print(f"Epoch: {epoch}")

    for batch_idx, (data, targets) in enumerate(train_loader):
        # Get data to device
        data = data.to(device=device)
        targets = targets.to(device=device)

        # Forward pass - no need to reshape for CNN!
        scores = cnn_model(data)
        loss = criterion(scores, targets)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

"""# Test CNN Accuracy"""

# Test accuracy function for CNN
def check_CNN_accuracy(loader, cnn_model):
    num_correct = 0
    num_samples = 0
    cnn_model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)

            # No reshaping needed for CNN
            scores = cnn_model(x)
            _, predictions = scores.max(1)

            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)

    print(f"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}%")

# Test the CNN
print("CNN Test accuracy:")
check_CNN_accuracy(test_loader, cnn_model)

# Define ResNet-specific transforms
resnet_transform = transforms.Compose([
    transforms.Resize(256),          # First resize to 256x256
    transforms.CenterCrop(224),      # Then crop to 224x224
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats
                         std=[0.229, 0.224, 0.225])
])

# Create datasets with ResNet transforms
resnet_train_dataset = SignLanguageDigits(
    root_dir='Sign-Language-Digits-Dataset/Dataset',
    shape=(64, 64),
    train=True,
    transform=resnet_transform
)

resnet_test_dataset = SignLanguageDigits(
    root_dir='Sign-Language-Digits-Dataset/Dataset',
    shape=(64, 64),
    train=False,
    transform=resnet_transform
)

# Create dataloaders
resnet_train_loader = DataLoader(resnet_train_dataset, batch_size=64, shuffle=True)
resnet_test_loader = DataLoader(resnet_test_dataset, batch_size=64, shuffle=False)

"""# ResNet with all freezed layers except last"""

# Load pre-trained ResNet and modify it
resnet1_model = models.resnet18(pretrained=True)

# Freeze all layers
for param in resnet1_model.parameters():
    param.requires_grad = False

# Modify final layer for 39 classes
num_features = resnet1_model.fc.in_features
resnet1_model.fc = nn.Linear(num_features, 39)  # 39 output classes

# Training setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet1_model = resnet1_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(resnet1_model.fc.parameters(), lr=0.001)  # Only train final layer

# Training loop
for epoch in range(10):
    resnet1_model.train()
    running_loss = 0.0
    for images, labels in resnet_train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = resnet1_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch+1}')

# Evaluation
def check_accuracy(loader, model):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%")

print("ResNet(all freezed layers) Test Accuracy:")
check_accuracy(resnet_test_loader, resnet1_model)

"""# ResNet with half freezed layers"""

resnet2_model = models.resnet18(pretrained=True)
# Get a list Of all the layers in the model
layers = list(resnet2_model .children())
# Determine the halfway point
halfway = len(layers) // 2
# Freeze the first half of the layers
for layer in layers[:halfway]:
    for param in layer.parameters():
        param.requires_grad = False

# Leave the second half of the layers unfrozen for fine-tuning
for layer in layers[halfway:]:
    for param in layer.parameters():
        param.requires_grad = True

# replace the last fully connected layer (fc) with a new one for 39-class classification
num_features = resnet2_model.fc.in_features
resnet2_model.fc = nn.Linear(num_features, 39) # 39 output classes


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet2_model = resnet2_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet2_model.parameters(), lr=1e-4)

# Training loop
for epoch in range(10):
    resnet2_model.train()
    running_loss = 0.0
    for images, labels in resnet_train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = resnet2_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch+1}')

# Evaluation
def check_accuracy(loader, model):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%")

print("ResNet 2 Test Accuracy:")
check_accuracy(resnet_test_loader, resnet2_model)

torch.save(resnet2_model.state_dict(), "/content/drive/MyDrive/resnet2_model_full.pth")
print("‚úÖ Weights saved successfully!")

"""# ResNet with only last Freezed layer"""

# Load pre-trained ResNet-18
resnet3_model = models.resnet18(pretrained=True)

# Unfreeze ALL layers for full fine-tuning
for param in resnet3_model.parameters():
    param.requires_grad = True  # All weights will be updated

# Replace final layer for 39-class classification
num_features = resnet3_model.fc.in_features
resnet3_model.fc = nn.Linear(num_features, 39)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet3_model = resnet3_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet3_model.parameters(), lr=1e-4)

# Training loop
for epoch in range(10):
    resnet3_model.train()
    running_loss = 0.0
    for images, labels in resnet_train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = resnet3_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch+1}')

# Evaluation
def check_accuracy(loader, model):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%")

print("ResNet 3 Test Accuracy:")
check_accuracy(resnet_test_loader, resnet3_model)

import torch
import matplotlib.pyplot as plt

# Make sure the model is in evaluation mode
resnet3_model.eval()

criterion = torch.nn.CrossEntropyLoss()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def evaluate(model, dataloader):
    model.eval()
    total, correct, running_loss = 0, 0, 0.0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * labels.size(0)

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = running_loss / total
    accuracy = 100 * correct / total
    return avg_loss, accuracy

# --- Evaluate on train and validation sets ---
train_loss, train_acc = evaluate(resnet3_model, resnet_train_loader)
val_loss, val_acc = evaluate(resnet3_model, resnet_test_loader)

print(f"Training Accuracy: {train_acc:.2f}%")
print(f"Validation Accuracy: {val_acc:.2f}%")
print(f"Training Loss: {train_loss:.4f}")
print(f"Validation Loss: {val_loss:.4f}")

# --- Plot bar chart for quick comparison ---
plt.figure(figsize=(6,4))
plt.bar(["Train Acc", "Val Acc"], [train_acc, val_acc], color=["skyblue","salmon"])
plt.title("Train vs Validation Accuracy")
plt.ylabel("Accuracy (%)")
plt.show()

plt.figure(figsize=(6,4))
plt.bar(["Train Loss", "Val Loss"], [train_loss, val_loss], color=["lightgreen","orange"])
plt.title("Train vs Validation Loss")
plt.ylabel("Loss")
plt.show()

"""Model over fitting"""

from torch.utils.data import random_split, DataLoader
import random

# Reproducibility
random.seed(42)
torch.manual_seed(42)

# Use your ORIGINAL dataset
full_dataset = resnet_train_dataset  # This contains all training data

# Define split sizes (80% train, 20% validation)
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size

# Randomly split into train and validation subsets (no overlap)
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# Create DataLoaders
resnet_train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
resnet_val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# ‚úÖ Verify that there is truly NO overlap
train_indices = set(train_dataset.indices)
val_indices = set(val_dataset.indices)

overlap_indices = train_indices & val_indices
print("Number of overlapping indices:", len(overlap_indices))

# ‚úÖ Optional: Check overlap by file paths
train_files = set([full_dataset.image_paths[i] for i in train_dataset.indices])
val_files = set([full_dataset.image_paths[i] for i in val_dataset.indices])
test_files = set(resnet_test_loader.dataset.image_paths)

print("Train ‚à© Val overlap:", len(train_files & val_files))
print("Train ‚à© Test overlap:", len(train_files & test_files))
print("Val ‚à© Test overlap:", len(val_files & test_files))

# Load pre-trained ResNet-18
resnet3_model = models.resnet18(pretrained=True)

# Unfreeze ALL layers for full fine-tuning
for param in resnet3_model.parameters():
    param.requires_grad = True  # All weights will be updated

# Replace final layer for 39-class classification
num_features = resnet3_model.fc.in_features
resnet3_model.fc = nn.Linear(num_features, 39)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet3_model = resnet3_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet3_model.parameters(), lr=1e-4)

# Training loop
for epoch in range(10):
    resnet3_model.train()
    running_loss = 0.0
    for images, labels in resnet_train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = resnet3_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch+1}')

# Evaluation
def check_accuracy(loader, model):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%")

print("ResNet 3 Test Accuracy:")
check_accuracy(resnet_test_loader, resnet3_model)

import torch
import matplotlib.pyplot as plt

# Make sure the model is in evaluation mode
resnet3_model.eval()

criterion = torch.nn.CrossEntropyLoss()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def evaluate(model, dataloader):
    model.eval()
    total, correct, running_loss = 0, 0, 0.0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * labels.size(0)

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = running_loss / total
    accuracy = 100 * correct / total
    return avg_loss, accuracy

# --- Evaluate on train and validation sets ---
train_loss, train_acc = evaluate(resnet3_model, resnet_train_loader)
val_loss, val_acc = evaluate(resnet3_model, resnet_test_loader)

print(f"Training Accuracy: {train_acc:.2f}%")
print(f"Validation Accuracy: {val_acc:.2f}%")
print(f"Training Loss: {train_loss:.4f}")
print(f"Validation Loss: {val_loss:.4f}")

# --- Plot bar chart for quick comparison ---
plt.figure(figsize=(6,4))
plt.bar(["Train Acc", "Val Acc"], [train_acc, val_acc], color=["skyblue","salmon"])
plt.title("Train vs Validation Accuracy")
plt.ylabel("Accuracy (%)")
plt.show()

plt.figure(figsize=(6,4))
plt.bar(["Train Loss", "Val Loss"], [train_loss, val_loss], color=["lightgreen","orange"])
plt.title("Train vs Validation Loss")
plt.ylabel("Loss")
plt.show()

torch.save(resnet3_model, "/content/drive/MyDrive/resnet3_model_full.pth")
print("‚úÖ Full ResNet-3 model saved successfully!")

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

"""Underperforming probably still overfitted

**Augmenting Data**
"""

# =============================================
# üß© DATASET + AUGMENTATION PIPELINE (AUGMENTED)
# =============================================

from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

# Strong augmentations for training
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomApply([
        transforms.ColorJitter(0.5, 0.5, 0.5, 0.2),
        transforms.RandomRotation(25),
        transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.GaussianBlur(3)
    ], p=0.8),
    transforms.ToTensor()
])
# For validation and test sets (no augmentation)
val_test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# =============================================
# üìÇ LOAD DATASET (update 'root_dir' to your dataset path)
# =============================================
root_dir = "/content/Sign-Language-Digits-Dataset"
full_dataset = datasets.ImageFolder(root=root_dir, transform=train_transform)

# Train / Val / Test split (e.g. 70/15/15)
train_size = int(0.7 * len(full_dataset))
val_size = int(0.15 * len(full_dataset))
test_size = len(full_dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])

# Apply val/test transforms correctly
val_dataset.dataset.transform = val_test_transform
test_dataset.dataset.transform = val_test_transform

# =============================================
# üöÄ DATA LOADERS
# =============================================
BATCH_SIZE = 32

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

print(f"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}")

# Load pre-trained ResNet-18
resnet3_model = models.resnet18(pretrained=True)

# Unfreeze ALL layers for full fine-tuning
for param in resnet3_model.parameters():
    param.requires_grad = True  # All weights will be updated

# Replace final layer for 39-class classification
num_features = resnet3_model.fc.in_features
resnet3_model.fc = nn.Linear(num_features, 39)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet3_model = resnet3_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet3_model.parameters(), lr=1e-4)

# Training loop
for epoch in range(10):
    resnet3_model.train()
    running_loss = 0.0
    for images, labels in resnet_train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = resnet3_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch+1}')

# Evaluation
def check_accuracy(loader, model):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%")

print("ResNet 3 Test Accuracy:")
print("val:")
check_accuracy(val_loader, resnet3_model)
print("test:")
check_accuracy(test_loader, resnet3_model)
print("train:")
check_accuracy(train_loader, resnet3_model)

# Load pre-trained ResNet-18
resnet3_model = models.resnet18(pretrained=True)

# Unfreeze ALL layers for full fine-tuning
for param in resnet3_model.parameters():
    param.requires_grad = True  # All weights will be updated

# Replace final layer for 39-class classification
num_features = resnet3_model.fc.in_features
resnet3_model.fc = nn.Linear(num_features, 39)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet3_model = resnet3_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(resnet3_model.parameters(), lr=1e-4)

# Training loop
for epoch in range(10):
    resnet3_model.train()
    running_loss = 0.0
    for images, labels in resnet_train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = resnet3_model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch+1}')

# Evaluation
def check_accuracy(loader, model):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print(f"Got {correct} / {total} with accuracy {float(correct)/float(total)*100:.2f}%")

print("ResNet 3 Test Accuracy:")
check_accuracy(resnet_test_loader, resnet3_model)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)



# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

# --- üì¶ Imports ---
from google.colab import files
from PIL import Image
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt

# --- üì§ Step 1: Upload images ---
uploaded = files.upload()  # choose one or more image files

# --- ü™Ñ Step 2: Prediction helper function ---
def predict_image(model, transform, image_path, class_names=None):
    """Loads an image, applies transform, and returns the predicted class index/name."""
    model.eval()
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, pred_class = torch.max(probs, 1)
        pred_idx = pred_class.item()
        conf_val = conf.item()

    # Show the image and prediction
    plt.imshow(img)
    plt.axis('off')
    if class_names:
        label = class_names[pred_idx]
        plt.title(f"Predicted: {label} ({conf_val*100:.1f}%)")
    else:
        plt.title(f"Predicted class index: {pred_idx} ({conf_val*100:.1f}%)")
    plt.show()

    return pred_idx, conf_val

# --- üßæ Step 3: Run predictions on uploaded images ---
# Optional: if you have a list of class names, define it
# Example: class_names = ['A', 'B', 'C', ..., 'Z', '1', '2', ..., '9']
class_names = None  # or replace with your actual label names

for fname in uploaded.keys():
    print(f"\nüîç Predicting for: {fname}")
    predict_image(resnet3_model, resnet_transform, fname, class_names)

"""Also performing well on test dataset ."""

torch.save(resnet3_model, "/content/drive/MyDrive/resnet3_model_full.pth")
print("‚úÖ Full ResNet-3 model saved successfully!")